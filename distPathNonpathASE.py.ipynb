{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "##\n",
    "### author: zhzhang\n",
    "### e-mail: zhzhang2015@sina.com / zhenhua.zhang@sina.com\n",
    "### date  : 2018.10.25\n",
    "##\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load necessary modules\n",
    "import os\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ct = time.clock()  # Time counting starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-30,14:46:07 <root> INFO: === Start ... ===\n"
     ]
    }
   ],
   "source": [
    "# Create stream handler of logging\n",
    "## Logging info formatter\n",
    "FORMATTER = '%(asctime)s <%(name)s> %(levelname)s: %(message)s'\n",
    "formatter = logging.Formatter(FORMATTER, '%Y-%m-%d,%H:%M:%S')\n",
    "\n",
    "## Set up main logging stream and formatter\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "# Set up logging\n",
    "lg = logging.getLogger()\n",
    "lg.setLevel(logging.INFO)         # default logging level INFO\n",
    "lg.addHandler(ch)\n",
    "lg.info(\"=== Start ... ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-30,14:46:09 <root> INFO: Load necessay modules...\n"
     ]
    }
   ],
   "source": [
    "# Load necessay modules\n",
    "lg.info('Load necessay modules...')\n",
    "import statsmodels.stats.multitest as mlt\n",
    "import matplotlib; matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-30,14:46:10 <root> INFO: Arrange working dirs...\n"
     ]
    }
   ],
   "source": [
    "# Arrange working dirs\n",
    "lg.info('Arrange working dirs...')\n",
    "hmDir = '/home/umcg-zzhang'\n",
    "pjDir = os.path.join(hmDir, 'projects', 'ASEpredictor')\n",
    "pjIpDir = os.path.join(pjDir, 'inputs')\n",
    "pjOpDir = os.path.join(pjDir, 'outputs', 'biosGavinOverlapCov10')\n",
    "pjSpDir = os.path.join(pjDir, 'scripts')\n",
    "pjMcDir = os.path.join(pjDir, 'miscellanies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-30,14:46:12 <root> INFO: Arrange input and output files...\n"
     ]
    }
   ],
   "source": [
    "# Arrange input and output files\n",
    "lg.info('Arrange input and output files...')\n",
    "pjIpFile = os.path.join(pjOpDir, 'biosGavinOverlapCov10Anno.tsv')\n",
    "pjOpUfFile = os.path.join(pjOpDir, 'biosGavinOverlapCov10AnnoUnFiltered.tsv')\n",
    "pjOpFcFile = os.path.join(pjOpDir, 'biosGavinOverlapCov10AnnoFilteredByLog2FC.tsv')\n",
    "pjOpAfFile = os.path.join(pjOpDir, 'biosGavinOverlapCov10AnnoFilteredByAf0.001.tsv')\n",
    "rawRdCtPlot = os.path.join(pjOpDir, 'rawReadCounts.png')\n",
    "rawLsRdCtPlot = os.path.join(pjOpDir, 'rawLess500ReadCounts.png')\n",
    "PCAPlot = os.path.join(pjOpDir, 'PCA.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-30,14:46:14 <root> INFO: Skipping data preprocessing, willl use output of last run...\n"
     ]
    }
   ],
   "source": [
    "# Conbinations pool of colors or markers\n",
    "pool = [['POPULATION', 'navy'], \n",
    "        ['BENIGN', 'turquoise'], \n",
    "        ['PATHOGENIC', 'darkorange'] ]\n",
    "markerDict = {10:'.', 11:'x'}\n",
    "\n",
    "if False:\n",
    "    # Loading file\n",
    "    lg.info(\"Reading file ...\")\n",
    "    df = pd.read_table(pjIpFile, header=0, low_memory=False)\n",
    "\n",
    "\n",
    "    # Filtering data\n",
    "    covSum = 10\n",
    "    fil = (df.refCountsBios + df.altCountsBios >= covSum) \\\n",
    "        & (df.refCountsBios > 0) \\\n",
    "        & (df.altCountsBios > 0)\n",
    "    lg.info(\"Filtering ...\")\n",
    "    df = df.loc[fil, :]\n",
    "\n",
    "\n",
    "    # Do exact binomial test\n",
    "    lg.info(\"Binomial test ...\")\n",
    "    df['pVal'] = df.loc[:, ['refCountsBios', 'altCountsBios']\n",
    "                   ].apply(stats.binom_test, axis=1)\n",
    "\n",
    "\n",
    "    # Two strategies for correction. One for all p values; two for each site.\n",
    "    ## Str 1. Considering all p values.\n",
    "    lg.info(\"Overall adjust ...\")\n",
    "    df['FDROverall'] = mlt.fdrcorrection(df.pVal)[1]\n",
    "\n",
    "    ## Str 2. Considering each variant\n",
    "    lg.info(\"Variant-wised adjust ...\")\n",
    "    dfGroups = df.groupby(['chr', 'pos', 'ref', 'alt'])\n",
    "    for name, group in dfGroups:\n",
    "        index = group.index\n",
    "\n",
    "        ## Adjustment of p-values because of multiple test\n",
    "        FDRPerVariant = mlt.fdrcorrection(group.pVal)[1]\n",
    "        df.loc[index, 'FDRPerVariant'] = FDRPerVariant\n",
    "\n",
    "        ## chi2_contigency test for the identical variant.\n",
    "        ctgTable = group.loc[:, ['refCountsBios', 'altCountsBios']]\n",
    "        g, p, dof, expctd = stats.chi2_contingency(ctgTable, lambda_='log-likelihood')\n",
    "        df.loc[index, 'varInsideChi2Pval'] = p\n",
    "\n",
    "\n",
    "    # Add coloumn of log2 fold change\n",
    "    lg.info(\"Calculating log 2 fold change ...\")\n",
    "    df['log2FC'] = ( df.loc[:, \"altCountsBios\"] / df.loc[:, 'refCountsBios']).apply(math.log2)\n",
    "\n",
    "    # Write Unfiltered Df in to a file\n",
    "    lg.info('Writing unfiltered file in to the drive ...')\n",
    "    df.to_csv(pjOpUfFile, header=True, index=False, sep='\\t')\n",
    "else:\n",
    "    df = pd.read_table(pjOpUfFile, header=0 , low_memory=False)\n",
    "    \n",
    "\n",
    "# Write DF filtered by AF and FDRPerVariant\n",
    "af = 0.001\n",
    "lg.info(\"Applying FILTER on unfiltered dataset ...\")\n",
    "dfFltAF = df[((df.gnomad_AF <= af)  & (df.FDRPerVariant <= 0.05))]\n",
    "\n",
    "lg.info('Writting DF filtered by AF and FDRPerVariant into the drive ...')\n",
    "dfFltAF.to_csv(pjOpAfFile, header=True, index=False, sep='\\t')\n",
    "\n",
    "lg.info('Removing extra variables ...')\n",
    "del dfFltAF\n",
    "\n",
    "# Write the filtered DF into a file\n",
    "lg.info(\"Applying FILTER on unfiltered dataset ...\")\n",
    "dfFltLog2FC = df[((df.log2FC >= 1) | (df.log2FC <= -1)) & (df.FDRPerVariant <= 0.05)]\n",
    "\n",
    "lg.info(\"Writing DF filtered by log2FC into the drive ...\")\n",
    "dfFltLog2FC.to_csv(pjOpFcFile, header=True, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Plots of raw read counts\\nlg.info(\"Start drawing ...\")\\nfig, axs = plt.subplots(ncols=4, sharey=True, sharex=True)\\n\\nfig.set_size_inches((40, 10))\\n\\nfor i, (g, c) in enumerate(pool):\\n    x = df.loc[df.group==g, \\'altCountsBios\\']\\n    y = df.loc[df.group==g, \\'refCountsBios\\']\\n    s = df.loc[df.group==g, \\'cadd\\']\\n    axs[i].scatter(x, y, c=c, s=s, alpha=0.5)\\n    axs[3].scatter(x, y, c=c, s=s, alpha=0.5)\\n    \\nplt.savefig(rawRdCtPlot)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Plots of raw read counts\n",
    "lg.info(\"Start drawing ...\")\n",
    "fig, axs = plt.subplots(ncols=4, sharey=True, sharex=True)\n",
    "\n",
    "fig.set_size_inches((40, 10))\n",
    "\n",
    "for i, (g, c) in enumerate(pool):\n",
    "    x = df.loc[df.group==g, 'altCountsBios']\n",
    "    y = df.loc[df.group==g, 'refCountsBios']\n",
    "    s = df.loc[df.group==g, 'cadd']\n",
    "    axs[i].scatter(x, y, c=c, s=s, alpha=0.5)\n",
    "    axs[3].scatter(x, y, c=c, s=s, alpha=0.5)\n",
    "    \n",
    "plt.savefig(rawRdCtPlot)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Plots of raw read counts(<=500)\\nlg.info('Drawing plots of records with less than 500 reads toally...')\\ndfLess500Rd = df[(df.altCountsBios + df.refCountsBios) <= 500]\\nfig, ax = plt.subplots()\\nfig.set_size_inches((40, 10))\\n\\nfor i, (g, c) in enumerate(pool):\\n    x = dfLess500Rd.loc[dfLess500Rd.group==g, 'altCountsBios']\\n    y = dfLess500Rd.loc[dfLess500Rd.group==g, 'refCountsBios']\\n    s = dfLess500Rd.loc[dfLess500Rd.group==g, 'cadd']\\n    ax.scatter(x, y, c=c, s=s, alpha=0.5)\\nplt.savefig(rawLsRdCtPlot)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Plots of raw read counts(<=500)\n",
    "lg.info('Drawing plots of records with less than 500 reads toally...')\n",
    "dfLess500Rd = df[(df.altCountsBios + df.refCountsBios) <= 500]\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches((40, 10))\n",
    "\n",
    "for i, (g, c) in enumerate(pool):\n",
    "    x = dfLess500Rd.loc[dfLess500Rd.group==g, 'altCountsBios']\n",
    "    y = dfLess500Rd.loc[dfLess500Rd.group==g, 'refCountsBios']\n",
    "    s = dfLess500Rd.loc[dfLess500Rd.group==g, 'cadd']\n",
    "    ax.scatter(x, y, c=c, s=s, alpha=0.5)\n",
    "plt.savefig(rawLsRdCtPlot)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# PCA analysis\\nlg.info('Doing PCA...')\\ncpPool = ['cadd', 'FDROverall', 'log2FC']\\ncpNum = len(cpPool)\\n\\npca = PCA(cpNum, whiten=True)\\n\\nX = df.loc[:, cpPool]\\nXFit = pca.fit(X)\\n\\nXreduced = pca.transform(X)\\ncovar = pca.get_covariance()\\n\\nlg.info('Plotting PCA results...')\\n# Plots for PCA analysis\\nfig, ax = plt.subplots()\\nfor g, c in pool:\\n    ax.scatter(\\n        Xreduced[df.group==g, 0], Xreduced[df.group==g, 1], \\n        c=c, marker='.', alpha=0.5)\\n\\nplt.savefig(PCAPlot)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# PCA analysis\n",
    "lg.info('Doing PCA...')\n",
    "cpPool = ['cadd', 'FDROverall', 'log2FC']\n",
    "cpNum = len(cpPool)\n",
    "\n",
    "pca = PCA(cpNum, whiten=True)\n",
    "\n",
    "X = df.loc[:, cpPool]\n",
    "XFit = pca.fit(X)\n",
    "\n",
    "Xreduced = pca.transform(X)\n",
    "covar = pca.get_covariance()\n",
    "\n",
    "lg.info('Plotting PCA results...')\n",
    "# Plots for PCA analysis\n",
    "fig, ax = plt.subplots()\n",
    "for g, c in pool:\n",
    "    ax.scatter(\n",
    "        Xreduced[df.group==g, 0], Xreduced[df.group==g, 1], \n",
    "        c=c, marker='.', alpha=0.5)\n",
    "\n",
    "plt.savefig(PCAPlot)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
